Federated Learning: Challenges, Methods, and Future Directions

作者：Tian Li; Anit Kumar Sahu ; Ameet Talwalkar; Virginia Smith

By 王浩竣

### 摘要

联邦学习涉及在远程设备或孤立的数据中心（例如手机或医院）上训练统计模型，同时使数据保持本地化。在异构网络和潜在大规模网络中进行的培训带来了新的挑战，这些挑战要求从根本上偏离用于大规模机器学习，分布式优化和隐私保护数据分析的标准方法。在本文中，我们讨论了联邦学习的独特特征和挑战，提供了当前方法的广泛概述，并概述了与广泛的研究社区相关的未来工作的几个方向。

### 1 介绍

![](http://img.wanghaojun.cn//img/20201102151251.png)

图1：联邦学习在手机上下一词预测任务中的示例应用。为了保护文本数据的私密性并减少网络压力，我们寻求以分布式方式训练预测变量，而不是将原始数据发送到中央服务器。在此设置中，远程设备会定期与中央服务器通信以学习全局模型。在每个通信回合中，选定电话的子集会对其不相同地分发的用户数据执行本地培训，并将这些本地更新发送到服务器。合并更新后，服务器会将新的全局模型发送回另一个设备子集。该迭代训练过程将在整个网络上继续进行，直到达到收敛或满足某些停止条件为止。

联邦学习方法已由主要服务提供商部署，并且在支持对隐私敏感的应用程序中发挥关键作用，在这些应用程序中，训练数据分布在边缘。潜在的应用示例包括：学习情绪，语义位置或移动电话用户的活动；适应自动驾驶汽车的行人行为；并预测可穿戴设备的健康事件，例如心脏病发作的风险。我们在下面讨论联邦学习的几种规范应用：

- 智能手机。通过联邦学习大量手机中的用户行为，统计模型可以为诸如下一词预测，面部检测和语音识别之类的应用提供支持[46，89]。但是，用户可能不愿意共享其数据以保护其个人隐私或节省电话的有限带宽/电池电量。联邦学习有可能在智能手机上启用预测功能，而不会减少用户体验或泄漏私人信息。图1描绘了一个这样的应用程序，我们的目标是根据用户的历史文本数据来学习大型移动电话网络中的下一个单词预测器
- 组织。在联邦学习的背景下，组织或机构也可以视为“设备”。例如，医院是包含用于预测性医疗保健的大量患者数据的组织。但是，医院在严格的隐私保护措施下运作，并且可能面临法律，行政或道德方面的限制，要求数据必须保持在本地。联邦学习是这些应用程序的有前途的解决方案[52]，因为它可以减轻网络的压力并支持各种设备/组织之间的私有学习。
- 物联网。诸如可穿戴设备，自动驾驶汽车或智能家居之类的现代物联网网络可能包含众多传感器，使它们能够实时收集，响应并适应传入的数据。例如，一群自动驾驶汽车可能需要交通，建筑或行人行为的最新模型才能安全运行。但是，由于数据的私有性和每个设备的连接性有限，在这些情况下构建汇总模型可能很困难。联邦学习方法可以帮助训练模型，以有效适应这些系统的变化，同时保持用户隐私。

#### 1.1 问题定义

规范的联邦学习问题涉及从存储在数十万到可能数百万个远程设备上的数据中学习单个全局统计模型。我们的目标是在设备生成的数据在本地存储和处理的约束下学习这种模型，只有中间更新会定期与中央服务器通信。特别地，目标通常是最小化以下目标函数：
$$
\min _{w} F(w), \text { where } F(w):=\sum_{k=1}^{m} p_{k} F_{k}(w)
\tag{1}
$$
$m$：设备的总数目；$p_k \ge 0 \& \sum_{k}p_k=1$；$ F_k$ 是第$k$个设备的本地目标函数；本地目标函数通常定义为本地的目标风险，

$F_{k}(w)=\frac{1}{n_{k}} \sum_{j_{k}=1}^{n_{k}} f_{j_{k}}\left(w ; x_{j_{k}}, y_{j_{k}}\right)$

$n_k$是本地的样本数；用户定义的$p_k$指每个设备的相对影响，通常有两种设定：$p_k=\frac{1}{n}$或者是$p_k=\frac{n_k}{n}$；$n=\sum_{k}n_k$，是整体的样本数。根据目标应用，其他目标或建模方法也可能适用。

#### 1.2 核心挑战

接下来，我们描述与解决（1）中提出的分布式优化问题相关的四个核心挑战。这些挑战使联邦设置有别于其他经典问题，例如数据中心设置中的分布式学习或传统的私有数据分析。

**挑战1：昂贵的通信**。通信是联邦网络中的一个关键瓶颈，再加上发送原始数据时的隐私问题，使得在每个设备上生成的数据必须保持本地状态。确实，联邦网络可能由大量设备组成，例如数百万部智能手机，并且网络中的通信可能比本地计算慢许多数量级[50，115]。为了使模型适合联邦网络中设备生成的数据，因此有必要开发一种通信效率高的方法，该方法可迭代地发送小消息或模型更新作为训练过程的一部分，而不是通过网络发送全部的数据集。为了在这种情况下进一步减少通信，要考虑的两个关键方面是：

- 减少通信回合的总数，
- 减少每个回合中传输的消息的大小。

**挑战2：系统异质性。**联邦网络中每个设备的存储，计算和通信功能可能会因硬件（CPU，内存），网络连接性（3G，4G，5G，WiFi）和电源（电池电量）的变化而有所不同。另外，每个设备的网络大小和与系统相关的约束通常导致仅一小部分设备立即处于活动状态，例如，一百万个设备网络中的数百个活动设备[11]。每个设备也可能是不可靠的，并且由于连接性或能量限制，活动设备在给定的迭代中掉线的情况并不少见。这些系统级的特性极大地加剧了诸如缓解流失和容错之类的挑战。因此，开发和分析的联邦学习方法必须：

- 预期参与量低，
- 容忍异构硬件，
- 对网络中丢失的设备具有鲁棒性。

**挑战3：统计异质性。**设备经常以不完全相同的方式在整个网络上生成和收集数据，例如，移动电话用户在下一个单词预测任务的上下文中使用了多种语言。此外，跨设备的数据点的数量可能有很大的不同，并且可能存在捕获设备之间的关系及其关联分布的底层结构。这种数据生成范例违反了分布式优化中经常使用的独立且相同分布（I.I.D.）的假设，增加了散乱的可能性，并可能增加建模，分析和评估方面的复杂性。确实，尽管（1）的规范联邦学习问题旨在学习单个全局模型，但存在其他替代方法，例如通过多任务学习框架同时学习不同的局部模型[cf.  106]。在这方面，联邦学习和元学习的领先方法之间也有紧密的联系[64]。多任务和元学习观点都支持个性化或特定于设备的建模，这通常是处理数据统计异质性的更自然的方法。

**挑战4：隐私问题。**最后，隐私通常是联邦学习应用程序中的主要问题。联邦学习迈出了一步，通过共享模型更新（例如梯度信息）而不是原始数据来保护在每个设备上生成的数据[17、31、33]。但是，在整个训练过程中交流模型更新仍然可以向第三方或中央服务器显示敏感信息[76]。尽管最近的方法旨在使用安全的多方计算或差分隐私等工具来增强联邦学习的隐私，但是这些方法通常以降低模型性能或系统效率为代价提供隐私。从理论上和经验上理解和平衡这些权衡，对于实现私有联邦学习系统是一个巨大的挑战。

### 2 当前相关工作汇总

#### 2.1 高效的通信

##### 2.1.1 本地更新

微型批处理优化方法涉及扩展经典的随机方法来一次处理多个数据点，已成为数据中心环境中分布式机器学习的流行范例[28、88、96、102、103]。然而，实际上，它们已被证明在适应通信计算权衡方面具有有限的灵活性，这将最大程度地利用分布式数据处理[107、108]。作为回应，已经提出了几种最近的方法来通过允许在每个通信回合上并行地将可变数量的本地更新应用于每台机器来提高分布式设置中的通信效率，从而使得计算量相对于通信量实质上更加灵活。对于凸优化，分布式局部更新原始对偶方法已经成为解决此类问题的一种流行方法[54，62，72，107，128]。这些方法利用对偶结构有效地将全局目标分解为子问题，可以在每个通信回合中并行解决这些子问题。还提出了几种分布式的局部更新原始方法，它们具有适用于非凸目标的额外好处[93，136]。这些方法在实践中可以极大地提高性能，并且在现实的数据中心环境中，已证明比传统的小批量方法或分布式方法（如ADMM  [14]）可实现数量级的加速。我们在图2中直观地说明了本地更新方法.

![](http://img.wanghaojun.cn//img/20201102160255.png)

图2：左图：分布式（mini-batch）SGD。每个设备$k$,从一小批数据点本地计算梯度到近似$\nabla F_{k}(w)$，然后聚合mini-batch的更新，并应用到服务器上。右图：本地更新模式。在计算每个设备后，每个设备都会立即应用本地更新（梯度），并在可变数量的本地更新后服务器执行全局聚合。本地更新方案可以通过在本地执行其他工作来减少通信。

在联邦设置中，允许灵活的本地更新和较少的客户参与的优化方法已成为事实上的求解器[65，75，106]。联邦学习最常用的方法是联邦平均（FedAvg）[75]，该方法基于对原始问题的本地随机梯度下降（SGD）更新进行平均的方法。已经证明FedAvg在经验上可以很好地工作，尤其是对于非凸问题，但是它没有收敛保证，并且在数据异构的情况下可以在实际环境中发散[65]。我们将在2.3.2节中更详细地讨论处理这种统计异质性的方法。

##### 2.1.2 压缩方案

虽然本地更新方法可以减少**通信回合的总数**，但是模型压缩方案（例如稀疏化，二次采样和量子化）可以显着减少每次回合传递的**消息大小**。在以前的文献中，已经针对数据中心环境中的分布式训练在经验和理论上对这些方法进行了广泛的研究。我们将读者推荐给[119，135]以进行更全面的评论。在联邦环境中，设备的低参与度，不相同地分布的本地数据和本地更新方案对这些模型压缩方法提出了新的挑战。例如，经典的分布式学习[101]中常用的错误补偿技术无法直接扩展到联邦设置，因为如果不频繁采样设备，本地累积的错误可能会过时。但是，有一些工作在联邦环境中提供了实用的策略，例如，强制更新模型稀疏且等级较低；用结构化随机旋转进行量化[59]；使用有损压缩和丢失来减少服务器到设备的通信[15]；并应用Golomb无损编码[99]。从理论上讲，尽管先前的工作已经探索了在存在不完全相同的数据的情况下进行低精度训练的收敛性保证[例如111]，但所做的假设并未考虑联邦环境的共同特征，例如低设备参与度或本地更新优化方法。

##### 2.1.3 分布式训练

![](http://img.wanghaojun.cn//img/20201102161850.png)

图3：集中vs分布。在典型的联邦学习设置中，并作为本文的重点，我们假设一个星型网络（左）中服务器与所有远程设备连接。当与服务器的通信成为瓶颈时，分散式拓扑（右）是一种潜在的替代方法。

在联邦学习中，星型网络（中央服务器连接到设备网络，如图3的左图所示）是主要的通信拓扑。因此，我们在本文中重点介绍星形网络设置。然而，我们简要地讨论了分散的拓扑（其中设备仅与它们的邻居通信，例如，图3的右面板）作为潜在的替代方案。在数据中心环境中，在低带宽或高延迟的网络上运行时，分散式培训已证明比集中式培训要快。我们将读者推迟到[47，67]进行更全面的评论。类似地，在联邦学习中，分散算法在理论上可以减少中央服务器上的高通信成本。最近的一些工作[47，61]已经使用本地更新方案研究了对异构数据的分散训练。但是，它们要么局限于线性模型[47]，要么假定完全参与设备[61]。最后，还提出了分层通信模式[68，70]来进一步减轻中央服务器的负担，通过首先利用边缘服务器来聚合来自边缘设备的更新，然后依靠云服务器来聚合来自边缘服务器的更新。尽管这是减少通信的一种有前途的方法，但它不适用于所有网络，因为这种类型的物理层次结构可能不存在或先验。

#### 2.2 系统异质性

![](http://img.wanghaojun.cn//img/20201102162245.png)



在联邦设置中，由于设备的硬件，网络连接性和电池电量可能会有所不同，因此整个网络的系统特性存在很大差异。如图4所示，与典型的数据中心环境相比，这些系统特性使诸如散乱的问题更加普遍。我们将处理系统异构性的几个关键方向大致分为以下几类：（i）异步通信，（ii）主动设备采样和（ii）容错。如2.1.3节所述，我们在以下讨论中采用星形拓扑。

##### 2.2.1 异步通信

在传统的数据中心设置中，同步和异步方案通常都用于并行化迭代优化算法，每种方法各有利弊。同步方案很简单，可以保证等效的串行计算模型，但是面对设备的可变性，它们也更容易受到混乱者的影响。异步方案是一种缓解异构环境中散乱现象的有吸引力的方法，尤其是在共享内存系统中[27、30、48、92、141]。但是，它们通常依赖于有界延迟的假设来控制陈旧程度，对于设备k，该陈旧程度取决于自设备k从中央服务器拉出以来已更新的其他设备的数量。虽然异步参数服务器已经在分布式数据中心中获得了成功[例如27、48、141]，但是经典的有界延迟假设在联邦设置中可能是不切实际的，因为这种设置的延迟可能在几小时到几天之间，或者是完全无限制的。

##### 2.2.2 主动采样

在联邦网络中，通常只有一小部分设备参加每次培训。但是，绝大多数联邦方法，例如[11、47、65、75、106]中描述的那些是被动的，因为它们并不旨在影响哪些设备参与。一种替代方法涉及在每个回合中主动选择参与设备。例如，Nishio和Yonetani  [83]基于系统资源探索了新颖的设备采样策略，其目的是使服务器在预定的时间窗口内聚集尽可能多的设备更新。同样，康等。  [57]在设计激励机制以鼓励具有更高质量数据的设备参与学习过程时，考虑了每个设备上的系统开销。但是，这些方法假定网络的系统特性为静态模型。如何扩展这些方法以处理在计算和通信延迟中实时的，特定于设备的波动，仍然是开放的。此外，尽管这些方法主要关注于执行主动采样的系统可变性，但我们注意到，也有必要考虑根据基础的统计结构主动采样一组小型但具有足够代表性的设备。

##### 2.2.3 容错

容错在系统界已被广泛研究，并且是经典分布式系统的基本考虑因素[19，71，110]。最近的工作还专门针对数据中心环境中的机器学习工作负载[例如87、112]研究了容错能力。然而，当通过远程设备学习时，容错变得更加重要，因为某些参与设备通常会在给定的训练迭代完成之前的某个时候退出[11]。一种实用的策略是简单地忽略此类设备故障[11]，如果故障设备具有特定的数据特征，则可能会在设备采样方案中引入偏差。例如，由于网络连接不良，来自偏远地区的设备可能更容易掉落，因此，经过训练的联邦模型将偏向具有良好网络条件的设备。从理论上讲，尽管最近有几项研究调查了联邦学习方法的变体的收敛性保证[56，123，131，132]，但很少有分析允许低参与度[例如65、106]，或直接研究掉落设备的影响。

编码计算是通过引入算法冗余来容忍设备故障的另一种选择。最近的工作已经探索使用编码来加快分布式机器学习训练的速度[例如20、21、63、94、109]。例如，在存在散乱的情况下，梯度编码及其变体[20、21、109]会在计算节点之间仔细复制数据块（以及这些数据块上的梯度计算），以获取真实值的精确或不精确恢复渐变。尽管这对于联邦设置来说似乎是很有前途的方法，但是由于隐私约束和网络规模的限制，这些方法在联邦网络中面临根本的挑战，因为跨设备共享数据/复制通常是不可行的。

#### 2.3 统计异构性

从数据建模不同的方面（如图5所示）以及分析关联的培训过程的收敛行为时，从跨设备分布不均的数据中训练联邦模型时会遇到挑战。我们在下面按照这些方向讨论相关工作。

![](http://img.wanghaojun.cn//img/20201102165423.png)

图5：联邦网络中的不同建模方法。根据数据，网络和感兴趣的应用程序的属性，可以选择（a）为每个设备学习单独的模型，（b）将单个全局模型适合所有设备，或者（c）在其中学习相关但不同的模型网络。

##### 2.3.1 建模异构数据

机器学习中有大量文献通过**元学习**[114]和**多任务学习**[18，37]等方法对统计异质性进行建模。这些想法最近已扩展到联邦环境[24、26、35、58、106、138]。例如，MOCHA  [106]是专为联邦设置而设计的优化框架，可以通过为每个设备学习单独但相关的模型来实现个性化，同时通过多任务学习来利用共享表示。扩展到大规模网络并仅限于凸目标。该方法为所考虑的目标提供了可证明的理论收敛保证，但在扩展到大规模网络的能力上受到限制，并且仅限于凸目标。另一种方法[26]将星形拓扑建模为贝叶斯网络，并在学习过程中执行变分推断。尽管此方法可以处理非凸模型，但将其推广到大型联邦网络的成本很高。  Khodak等。 [58]可证明地使用多任务信息（其中每个任务对应于一个设备）元学习任务内学习率，并且已经证明了比香草FedAvg更好的经验性能。  Eichner等。 [35]研究了一种多元解决方案（在全局模型和特定于设备的模型之间自适应选择）以解决联邦训练期间数据样本中的循环模式。赵等。  [138]在集中训练一些共享代理数据的全局模型后，通过运行FedAvg探索转移学习的个性化。尽管取得了这些最新进展，但仍需要在联邦环境中为鲁棒性，可伸缩性和自动化的异构建模方法中建立关键挑战。

在对联邦数据进行建模时，考虑准确性以外的问题（例如公平性）也可能很重要。特别是，天真地解决（1）中的总损失函数可能会隐含某些设备的优势或劣势，因为学习的模型可能会偏向于具有大量数据的设备，或者（如果对设备进行加权）出现的设备组。最近的工作提出了改进的建模方法，旨在减少跨设备的模型性能差异。一些启发式方法只是基于局部损失来执行各种局部更新[52]。其他更原则的方法包括Agnostic  Federated Learning [80]，它通过minimax优化方案针对由客户端分布的混合所形成的任何目标分布，优化集中式模型。  Li等人采用了另一种更通用的方法。  [66]提出了一个称为q-FFL的目标，其中具有较高损耗的设备具有较高的相对权重，以鼓励最终精度分布中的变化较小。除了公平问题之外，我们注意到，联邦学习中的责任制和可解释性等方面还值得探讨，但由于网络的规模和异构性，可能具有挑战性。

##### 2.3.2 非IID数据的收敛保证

统计异质性在分析联邦环境中的收敛行为方面（即使在学习单个全局模型时）也提出了新的挑战。确实，当数据在网络中的设备之间分布不相同时，在实践中已证明诸如FedAvg之类的方法会有所不同[65，75]。在I.I.D.中已经分析了并行SGD和相关变体，它们使本地更新类似于FedAvg。设置[68，93，104，108，120，121，122，125，136，140]。但是，结果依赖于这样的前提，即每个本地求解器都是同一随机过程的副本（由于I.I.D.的假设），在典型的联邦设置中情况并非如此。为了了解FedAvg在统计异构环境中的性能，最近提出了FedProx  [65]。 FedProx对FedAvg方法进行了少量修改，以帮助确保理论上和实践上的收敛。  FedProx也可以解释为FedAvg的广义重新参数化版本，在考虑跨设备的系统异质性的情况下具有实际的影响。其他几项工作[56，123，131，132]也探索了在具有不同假设（例如，凸度[123]或均匀边界梯度[131]）的异构数据的情况下的收敛保证。还有一些启发式方法旨在通过共享本地设备数据或某些服务器端代理数据来解决统计上的异质性[52、55、138]。但是，这些方法可能是不现实的：除了给网络带宽带来负担外，将本地数据发送到服务器[55]违反了联邦学习的关键隐私假设，并且将全局共享的代理数据发送到所有设备[52，138]需要努力来仔细生成或收集此类辅助数据。

#### 2.4 隐私

出于隐私考虑，通常需要在联邦设置中将每个设备上的原始数据保留在本地。但是，作为训练过程的一部分，共享其他信息（例如模型更新）也会泄漏敏感的用户信息[8、17、39、78]。例如，Carlini等。  [17]演示了可以从经过用户语言数据训练的循环神经网络中提取敏感的文本模式，例如特定的信用卡号。鉴于人们越来越关注隐私保护学习方法，在第2.4.1节中，我们首先简要回顾一下以前在通用（分布式）机器学习环境中增强隐私的工作。然后，我们将在2.4.2节中回顾专门为联盟设置而设计的最新隐私保护方法。

##### 2.4.1 机器学习中的隐私

机器学习[例如76]，系统[例如4、11]和理论[例如38、69]社区已广泛研究了保护隐私的学习。我们将简要回顾以下三种主要策略，其中包括差异性隐私以传达嘈杂的数据草图，同态加密以对加密数据进行操作以及安全功能评估或多方计算。

在这些各种隐私方法中，差分隐私[32、33、34]由于其强大的信息理论保证，算法简单性以及相对较小的系统开销而被广泛使用。简而言之，如果一个输入元素的变化不会导致输出分布的太大差异，则随机机制是差分私有的。这意味着，对于学习过程中是否使用了特定样本，无法得出任何结论。这样的样本级隐私可以在许多学习任务中实现[2、7、22、53、85、86]。对于基于梯度的学习方法，一种流行的方法是通过在每次迭代时随机地扰动中间输出来应用差分隐私[例如2、7、126]。在应用扰动之前，例如通过高斯噪声[2]，拉普拉斯噪声[77]或二项式噪声[3]，通常会限制梯度以限制每个示例对整体更新的影响。在差分隐私和模型准确性之间存在固有的权衡，因为添加更多的噪声会导致更大的隐私，但可能会严重影响准确性。尽管事实上差异隐私是机器学习中隐私的事实度量标准，但仍有许多其他隐私定义，例如k-匿名[36]，δ-存在[81]和距离相关[117]，可能适用针对不同的学习问题[118]。

除了差分隐私之外，同态加密可用于通过对加密数据进行计算来确保学习过程的安全，尽管当前它已被应用于有限的设置中，例如训练线性模型[82]或仅涉及少数几个实体[133]。当敏感数据集分布在不同的数据所有者之间时，另一个自然的选择是通过安全功能评估（SFE）或安全多方计算（SMC）执行隐私保护学习。所产生的协议可使多方协作地计算同意的功能，而不会泄漏任何一方的输入信息，除非可以从输出中推断出什么[例如，23、43、95]。因此，尽管SMC不能保证防止信息泄漏，但可以将其与差分隐私结合使用以实现更强的隐私保证。但是，沿着这些思路的方法可能不适用于大规模机器学习方案，因为它们会招致大量额外的通信和计算成本。此外，需要针对目标学习算法中的每个操作精心设计和实现SMC协议[25，79]。我们将感兴趣的读者推迟到[13，97]，以对基于同态加密和SMC的方法进行更全面的回顾。

##### 2.4.2 联邦学习中的隐私

联邦设置对现有的隐私保护算法提出了新的挑战。除了提供严格的隐私保证外，还必须开发一种计算上便宜，通信效率高并且可以容忍掉线设备的方法-所有这些都不会过度影响准确性。尽管联邦学习中存在各种隐私定义[8、17、41、64、76、113]，但通常可以将它们分为两类：**全局隐私**和**本地隐私**。如图6所示，全局隐私要求在每个回合中生成的模型更新对于除中央服务器以外的所有不受信任的第三方都是私有的，而本地隐私还要求更新对于服务器也是私有的。

当前旨在改善联邦学习隐私的工作通常基于先前的经典密码协议，例如SMC [10，42]和差分隐私[3，8，41，76]。 Bonawitz等10]引入了SMC协议来保护单个模型更新。中央服务器无法看到任何本地更新，但是仍然可以在每个回合中观察到确切的汇总结果。  SMC是一种无损方法，可以保留原始准确性并具有很高的隐私保证。但是，所得到的方法导致相当大的额外通信成本。其他工作[41，76]将差异隐私应用于联邦学习并提供全局差异隐私。这些方法有许多影响通信和准确性的超参数，必须认真选择，尽管后续工作[113]提出了自适应梯度限幅策略来帮助缓解这一问题。在需要更强的隐私保证的情况下，Bhowmick等人[8]通过限制潜在对手的力量，引入了宽松的本地隐私版本。与全局隐私相比，它提供了更加强大的隐私保证，与严格的本地隐私相比，它具有更好的模型性能。 Li等[64]在元学习的背景下提出了局部差分私有算法，该算法可以应用于具有个性化的联邦学习，同时在凸设置中提供可证明的学习保证。另外，差分隐私可以与模型压缩技术结合使用，以减少通信并同时获得隐私利益[3]。

### 3 未来研究方向

联邦学习是一个活跃而持续的研究领域。尽管最近的工作已开始解决第2节中讨论的挑战，但仍有许多关键的开放方向需要探索。在本节中，我们简要概述了围绕先前讨论的挑战（昂贵的通信，系统异质性，统计异质性和隐私问题）的一些有前途的研究方向，并介绍了有关诸如联邦环境中的生产和基准测试等问题的其他挑战。

**极限通信方案**。联邦学习中需要多少沟通还有待观察。的确，众所周知，机器学习的优化方法可以容忍缺乏精确性。这个错误实际上可以帮助推广[129]。尽管在传统的数据中心设置中已经探索了单发或分而治之的通信方案[73，137]，但是在大规模或统计异构网络中，这些方法的行为并没有得到很好的理解。类似地，最近针对联邦设置提出了单发/几发启发式方法[44、45、134]，但尚未在理论上进行大规模分析或评估。

**减少通信和帕累托边界**。我们讨论了减少联邦训练中的交流的几种方法，例如本地更新和模型压缩。为了创建一个用于联邦学习的现实系统，重要的是要了解这些技术如何相互结合，并针对每种方法系统地分析准确性和交流之间的权衡。特别是，最有用的技术将在帕累托（Pareto）边界上展示出改进-在相同的通信预算下，并且理想地在广泛的通信/准确性配置文件中，其准确性要高于任何其他方法。为了进行有效的神经网络推理，已经进行了类似的综合分析[9]，这对于以有意义的方式比较用于联邦学习的交流减少技术是必要的

**新颖的异步模型。**如第2.2.1节所述，在分布式优化中最常研究的两种通信方案是批量同步方法和异步方法（假定延迟是有界的）。这些方案在数据中心设置中更切合实际，其中工作节点通常专用于工作负载，即，它们准备好在“推送”先前工作的结果后立即从中央节点“拉”下一份工作。相反，在联邦网络中，每个设备通常不专用于手头的任务，并且大多数设备在任何给定的迭代中都不活动。因此，值得研究这种更现实的以设备为中心的通信方案的效果，在该方案中，每个设备都可以决定何时以事件触发的方式“唤醒”并与中央服务器进行交互。

**异质性诊断。**最近的工作旨在通过度量标准来量化统计异质性，例如局部差异（在[65]中定义为联邦学习的背景下，并在[100，116，130]等工作中用于其他目的）和推土机的距离[138]  ]。但是，在进行训练之前，无法通过联邦网络轻松计算这些指标。这些指标的重要性引发了以下未解决的问题：（i）是否存在简单的诊断程序来快速确定先验联邦网络中的异质性水平？  （ii）是否可以开发类似的诊断方法来量化与系统相关的异质性数量？ （iii）是否可以利用当前或新的异质性定义来进一步改善联邦优化方法的收敛性？

**严格的隐私限制**。隐私的定义在本地或全球范围相对于网络中的所有设备中第2.4.2盖隐私概述。但是，实际上，可能有必要在更精细的级别上定义隐私，因为隐私约束可能在设备之间甚至在单个设备上的数据点之间都不同。例如，Li等。  [64]最近提出了特定于样本（相对于特定于用户）的隐私保证，从而提供了一种较弱的隐私形式，以换取更准确的模型。开发处理混合（特定于设备或特定于样本）隐私限制的方法是未来工作的有趣且持续的方向。

**除了监督学习。**重要的是要注意，到目前为止讨论的方法是在监督学习任务的基础上开发的，即，它们假定联邦网络中所有数据都存在标签。实际上，在现实的联邦网络中生成的许多数据可能是未标记的或标记较弱的。此外，眼前的问题可能不是要使模型适合于（1）中所述的数据，而是要执行一些探索性数据分析，确定汇总统计数据或运行更复杂的任务，例如强化学习。解决联邦网络中监督学习之外的问题可能需要解决可伸缩性，异构性和隐私性的类似挑战

**联邦学习的生产环境。**除了本文讨论的主要挑战之外，在生产环境中运行联邦学习时还存在许多实际问题。特别是诸如概念漂移之类的问题（当基础数据生成模型随时间变化时）；日变化（当设备在一天或一周的不同时间表现出不同的行为时）[35]；冷启动问题（当新设备进入网络时）必须小心处理。我们将读者推向[11]，它讨论了生产联邦学习系统中存在的一些与系统相关的实际问题。

**基准。**最后，由于联邦学习是一个新生领域，因此我们正处于关键时刻，以决定该领域的发展，并确保它们立足于现实世界的设置，假设和数据集。对于更广泛的研究社区而言，至关重要的是要进一步利用现有的实施和基准测试工具，例如LEAF  [16]和TensorFlow Federated [1]，以促进经验结果的可再现性和新的联邦学习解决方案的传播。

### 4 总结

在本文中，我们概述了联邦学习，这是一种学习范例，其中统计模型在分布式网络的边缘进行了训练。与传统的分布式数据中心计算和经典的隐私保护学习相比，我们已经讨论了联邦学习的独特属性和相关挑战。我们提供了有关经典结果的广泛调查，以及针对联邦环境的最新工作。最后，我们概述了一些尚待进一步研究的13个未解决的问题。提供这些问题的解决方案将需要众多研究团体的跨学科研究。