**A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection**  

[toc]



### 摘要

联邦学习一直是在隐私限制下实现不同组织之间机器学习模型的协作训练的热门研究主题。 随着研究人员尝试使用不同的隐私保护方法来支持更多的机器学习模型，开发系统和基础架构的需求就要求简化各种联邦学习算法的开发。 与促进深度学习发展的深度学习系统（例如PyTorch和TensorFlow）相似，联邦学习系统（FLS）同样重要，并且面临着来自有效性，效率和隐私等各个方面的挑战。 在这项调查中，我们对联邦学习系统进行了全面的审查。 为了实现顺畅的流程并指导未来的研究，我们介绍了联邦学习系统的定义并分析了系统组件。 此外，我们根据数据分发，机器学习模型，隐私机制，通信体系结构，联盟规模和联盟动机等六个不同方面对联盟学习系统进行了彻底的分类。 如我们的案例研究所示，分类可以帮助设计联合学习系统。 通过系统地总结现有的联合学习系统，我们介绍了设计因素，案例研究和未来的研究机会。

### 1 引言

许多机器学习算法都需要大量数据，实际上，在隐私限制的保护下，数据分散在不同的组织中。 由于这些因素，联邦学习（FL）[159]已成为机器学习中的热门研究主题。 例如，不同医院的数据是孤立的，成为“数据孤岛”。 由于每个数据岛在大小和实际分布上都有局限性，因此一家医院可能无法训练高质量的模型，该模型对于特定任务具有良好的预测准确性。 理想情况下，如果医院可以结合其数据来共同训练机器学习模型，则可以从中受益更多。 然而，由于各种政策和法规，数据不能简单地在医院之间共享。 在“数据岛”上的这种现象在金融，政府和供应链等许多领域都很普遍。 通用数据保护条例（GDPR）[11]等政策规定了不同组织之间的数据共享规则。 因此，开发一种具有良好的预测准确性同时遵守政策和法规以保护隐私的联邦学习系统具有挑战性。

最近，人们为实现联合学习算法进行了许多努力，以支持有效的机器学习模型。 具体来说，研究人员尝试使用不同的隐私保护方法来支持更多的机器学习模型，包括深度神经网络（NN）[114、205、25、148、122]，梯度增强决策树（GBDT）[208、44、103]  ，物流回归[134，41]和支持向量机（SVM）[162]。 例如，Nikolaenko等。  [134]和Chen等。  [41]提出了基于线性回归进行FL的方法。 哈代等。  [77]实现了FL框架来训练逻辑回归模型。 由于GBDT近年来非常成功[38，190]，因此Zhao等人也提出了相应的联邦学习系统（FLS）。  [208]，Cheng等。  [44]，Li等。  [103]。 决策树的另一种流行的集成方法，即随机森林，也已扩展为支持隐私保护[144]，这是支持FL的重要一步。 此外，有许多基于神经网络的FLS。  Google提出了一种可扩展的生产系统，该系统可以使数千万个设备训练深度神经网络[25]。  Yurochkin等。  [205]通过应用贝叶斯非参数机制，为神经网络开发了概率FL框架。 几种方法尝试将FL与机器学习技术相结合，例如多任务学习和转移学习。 史密斯等。  [162]结合FL与多任务学习，以允许多方完成单独的任务。 为了解决仅在一方中存在标签信息的情况，Yang等人（2002）提出。  [197]采用迁移学习来协作学习模型。

在关于联合上下文下定制机器学习算法的研究中，我们确定了一些常用的方法和方法。 以提供隐私保证的方法为例。 一种常见的方法是使用加密技术[24]，例如安全的多方计算[126]和同态加密[77]。 另一种流行的方法是差异隐私[208]，它会向模型参数添加噪声以保护个人记录。 例如，Google的FLS [24]同时采用了安全汇总和差异隐私，以增强隐私保护。

由于存在构建FL算法的通用方法和构件，因此开发系统和基础结构以简化各种FL算法的开发是有意义的。 系统和基础架构允许算法开发人员重用常见的构建模块，并避免每次从头开始构建算法。 类似于促进深度学习算法发展的PyTorch [140，141]和TensorFlow [8]等深度学习系统，FLS对于FL的成功同样重要。 但是，构建成功的FLS具有挑战性，需要考虑多个方面，例如有效性，效率，隐私和自治。

在本文中，我们从系统角度对现有的FLS进行了调查。 首先，我们显示FLS的定义，并将其与常规联合系统进行比较。 其次，我们分析FLS的系统组件，包括各方，管理者和计算通信框架。 第三，我们基于六个不同方面对FLS进行分类：数据分发，机器学习模型，隐私机制，通信体系结构，联盟规模和联盟动机。 这些方面可以将FLS的设计指导为常见的构建基块和系统抽象。 第四，基于这些方面，我们系统地总结了现有研究，可用于指导FLS的设计。 最后，为使FL更加实用和强大，我们提出了未来的研究方向。 我们认为，系统和基础架构对于FL的成功至关重要。 为了解决系统研究在有效性，效率，隐私和自治方面的问题，还需要做更多的工作。

#### 1.1 相关调查

关于FL有一些调查。  Yang等人撰写的开创性调查。  [197]介绍了FL的基础和概念，并进一步提出了一个全面的安全FL框架。 后来，WeBank [187]发布了一份白皮书，介绍FL的背景和相关工作，最重要的是提出了发展路线图，包括建立本地和全球标准，建立用例并形成工业数据联盟。 本文主要针对相对较少的参与者，这些参与者通常是企业数据所有者。  Lim等。  [109]进行了针对移动边缘计算的FL的调查。  Li等。  [105]总结了移动和边缘设备的大规模网络中FL的挑战和未来方向。 最近，Kairouz等人。  [85]对来自不同研究主题的FL的特征和挑战进行了全面的描述。 但是，他们主要关注跨设备FL，其中参与者是大量的移动或IoT设备。

#### 1.2 我们的贡献

据我们所知，目前尚缺乏一项关于审查FLS的现有系统和基础结构以及如何提高创建FL系统的注意力的调查（类似于深度学习中繁荣的系统研究）。 与以前的调查相比，本文的主要贡献如下。  （1）我们的调查是第一个从系统的角度对FL进行全面分析的调查，包括系统组件，分类法，摘要，设计和愿景。  （2）我们针对FLS提供六个方面的综合分类法，包括数据分发，机器学习模型，隐私机制，通信体系结构，联盟规模和联盟动机，它们可以作为FLS的常见构建块和系统抽象 。  （3）我们根据领域对现有的典型和最新研究进行了总结，以方便研究人员和开发人员参考。  （4）我们介绍了成功实施FLS的设计因素，并针对每种情况全面审查了解决方案。  （5）我们为子孙后代提出了有趣的研究方向和挑战。

本文的其余部分安排如下。 在第2节中，我们介绍FLS的概念，并将其与传统的联合系统进行比较。 在第3节中，我们介绍FLS的系统组件。在第4节中，我们提出了六个方面来对FLS进行分类。 在第5节中，我们总结了关于FL的现有研究和系统。 然后，在第6节中介绍FLS的设计因素和解决方案。接下来，在第7节中，我们将展示两个针对系统特性的案例研究。 最后，我们在第8节中提出关于FL的未来可能方向，并在第9节中总结我们的论文。

### 2 联邦学习系统概述

#### 2.1 背景

近年来，数据泄露严重威胁了用户的数据隐私。 在2019年的一次重大泄密事件中，超过5.4亿条有关Facebook用户的记录在亚马逊的云中暴露[3]。  2019年，美国海关和边境保护局宣布数据泄漏，成千上万的旅行者照片被盗[6]。

随着数据泄露成为一个主要问题，越来越多的政府制定了保护用户数据的法规，例如欧盟的GDPR [178]，新加坡的PDPA [45]和美国的CCPA [1]。 对于公司而言，违反这些政策的成本非常高。  2016年，Uber不得不支付1.48亿美元，以结束调查[60]，从而违反了600,000个驾驶员的个人信息。  SingHealth因违反PDPA被新加坡政府罚款750,000美元[5]。  Google因违反GDPR [4]被罚款5700万美元，这是根据欧盟隐私法，截至2020年3月18日的最高刑罚。

#### 2.2 定义

在上述情况下，联邦学习是一种无需交换用户原始数据的协作学习，如今受到越来越多的关注。 尽管机器学习，尤其是深度学习在最近再次引起了很多关注，但联合身份验证和机器学习已成为一个新的热门研究主题。  FL使多方可以共同训练机器学习模型，而无需交换本地数据。 它涵盖了来自多个研究领域的技术，例如分布式系统，机器学习和隐私。 这里我们给出FLS的正式定义

我们假设有$N$个不同的参与方，每个参与方用$T_i$表示，其中i  ∈[1， N]。 我们用$D_i$表示$T_i$的数据。 对于非联合设置，每个参与方$T_i$仅使用其本地数据$D_i$来训练机器学习模型$M_i$。  $M_i$的预测精度表示为$P_i$。 对于联合设置，所有各方共同训练模型$\hat{M}_{f}$，而每一方$T_i$根据其特定的隐私限制保护其数据$D_i$。  $\hat{M}_{f}$的预测精度表示为$\hat{P}_{f}$。 然后，对于有效的FLS，存在i  ∈[1， N]，使得$\hat{P}_{f}$>$P_i$。

请注意，在以上定义中，我们仅要求存在任何一方可以通过FL获得更高的模型质量。 即使某些参与方可能无法从FL获得更好的模式，但他们仍然可以加入联邦并与其他参与方达成协议，要求其他形式的激励措施（例如金钱）

#### 2.3与常规联邦系统比较

联盟的概念可以在商业和体育等现实世界中找到。联盟的主要特征是合作。 联合不仅在社会中普遍出现，而且在计算中也起着重要作用。 在计算机科学中，联邦计算系统已成为不同背景下的一个有吸引力的研究领域。

在1990年左右，有很多关于联邦数据库系统（FDBS）的研究[158]。  FDBS是合作互利的自治数据库的集合。 正如先前的研究[158]所指出的那样，FDBS的三个重要组成部分是自治性，异构性和分布性。

- **自治.**参与FDBS的数据库系统（DBS）是自治的，这意味着它受到单独和独立的控制。 各方仍然可以在没有FDBS的情况下管理数据。

- **异质性.**FDBS内部的数据库管理系统可以不同。 例如，差异可能在于数据结构，查询语言，系统软件要求和通信功能。
- **分布.**由于在构建FDBS之前存在多个DBS，因此不同DBS中的数据分布可能会有所不同。 数据记录可以水平或垂直划分为不同的DBS，也可以在多个DBS中复制以提高可靠性。

最近，随着云计算的发展，已经对联邦云计算进行了许多研究[97]。 联合云（FC）是多个外部和内部云计算服务的部署和管理。 云联合的概念由于将部分外包给更具成本效益的区域而能够进一步降低成本。 资源迁移和资源冗余是联合云的两个基本特征[97]。 首先，资源可以从一个云提供商转移到另一个云提供商。 迁移可以重新分配资源。 其次，冗余允许在不同域中并发使用相似的服务功能。 例如，可以按照相同的计算逻辑在不同的提供者处对数据进行分区和处理。 总体而言，不同资源的调度是联邦云系统设计中的关键因素。

**对现有联邦系统的观察.**FLS与常规联合系统之间存在一些异同。 一方面，联盟的概念仍然适用。共同的基本思想是关于多个独立方的合作。 因此，考虑当事方之间的异质性和自治性的观点仍然可以应用于FLS。此外，分布式系统设计中的某些因素对于FLS仍然很重要。 例如，各方之间如何共享数据会影响系统的效率。 另一方面，这些联合系统在协作和约束方面有不同的强调。  FDBS专注于分布式数据的管理，FC专注于资源的调度，而FLS则更关注多方之间的安全计算。  FLS带来了新的挑战，例如分布式培训的算法设计和隐私限制下的数据保护。

**图1**显示了这三个研究领域每年的论文数量。 在这里，我们通过在Google Scholar1中搜索关键字“联合数据库”，“联合云”和“联合学习”来对论文进行计数。 尽管联邦数据库是30年前提出的，但近年来仍然有大约400篇论文提到了该数据库。 最初，联合云的普及率比联合数据库的增长速度快，而近年来它似乎在下降，这可能是因为云计算变得更加成熟并且联合的动机减弱了。 对于FL，相关论文的数量正在迅速增加，去年已达到1,200。 如今，“数据岛”现象很普遍，并且已日益成为机器学习中的重要问题。 另外，公众越来越关注隐私和社会意识。 因此，我们预计FL的普及程度至少会持续五年，直到FLS可能成熟为止。

![](https://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsfigure1.PNG)

-------------------------------------------------

图1：有关“联合数据库”，“联合云”和“联邦学习”的相关论文数量

### 3 系统组件

FLS中包含三个主要组件：参与者（例如，客户），管理者（例如，服务器）以及用于训练机器学习模型的通信计算框架。

#### 3.1参与者

在FLS中，双方都是FL的数据所有者，也是FL的受益人。 它们可以是组织或移动设备，分别称为跨库或跨设备设置[85]。 我们可以考虑可能影响FLS设计的各方的以下属性。

首先，双方的硬件容量是多少？ 硬件容量包括计算能力和存储量。 如果当事方是移动电话，则容量很弱，并且当事方无法执行大量计算和训练庞大的模型。 例如，Wang等。  [184]考虑了FL中的资源受限设置。 他们设计了一个包括资源预算的目标，并提出了一种算法来确定各轮本地更新。

第二，双方的规模和稳定性如何？ 对于组织而言，与移动设备相比，规模相对较小。 同样，跨筒仓设置的稳定性比跨装置设置更好。 因此，在跨孤岛设置中，我们可以做到每个人都可以在整个联合过程中连续执行计算和通信任务，这在许多研究中都是常见的设置[103、44、162]。 如果各方是移动设备，则系统必须处理可能的问题，例如连接丢失[25]。 此外，由于设备的数量可能很大（例如，数百万），所以假设所有设备都参与FL中的每一轮都是不切实际的。 广泛使用的设置是在每一轮中选择一部分设备进行计算[122，25]。

最后，各方之间的数据分配是什么？ 通常，无论跨设备设置还是跨系统设置，在联合学习中，非IID（相同且独立分布）的数据分布都被认为是一种实用且具有挑战性的设置[85]，该功能在最近的工作实验中得到了评估。  [103、205、108、182]。 在组织之间，这种非IID数据分发可能更加明显。例如，银行和保险公司可以进行FL改进其预测（例如，一个人是否可以偿还贷款以及该人是否可以购买保险产品），而在这些组织中，甚至功能也可能有很大不同。 转移学习[139]，元学习[59]和多任务学习[147]中的技术可能对组合各种参与方的知识很有用。

#### 3.2管理者

在跨设备设置中，管理器通常是功能强大的中央服务器。 它进行全局机器学习模型的培训，并管理各方与服务器之间的通信。 服务器的稳定性和可靠性非常重要。 一旦服务器无法提供准确的计算结果，FLS可能会生成错误的模型。 为了解决这些潜在的问题，区块链[168]可能是一种提供去中心化解决方案以提高系统可靠性的技术。 例如，Kim等。  [93]利用区块链代替系统中的中央服务器，在该系统中，区块链可以交换设备的更新并为其提供奖励。

在跨仓库环境中，由于期望组织拥有强大的机器，因此经理也可以是主导FL流程的组织之一。 这在垂直FL [197]中特别使用，我们将在4.1节中详细介绍。 在Liu等人的垂直FL设置中。  [114]，数据的特征在各方之间垂直划分，只有一方具有标签。 拥有标签的一方自然被视为FL经理。

一个问题可能是，很难找到受信任的服务器或参与方作为管理者，尤其是在跨孤岛设置中。 然后，完全分散的环境可能是一个不错的选择，各方之间可以直接沟通，几乎可以平等地参与全球机器学习模型的培训。 在这里，经理实际上是所有各方。 这些各方共同制定FL任务并部署FLS。  Li等。 [103]提出了一个联邦梯度提升决策树框架，其中每一方都按顺序训练决策树，最终模型是所有树的组合。 设计具有合理通信开销的完全分散的FLS具有挑战性。

#### 3.3通讯计算框架

在FLS中，计算发生在各方和管理者之间，而通信发生在各方和管理者之间。 通常，计算的目的是为了模型训练，而通信的目的是为了交换模型参数。

基本且广泛使用的框架是2016年提出的联邦平均（FedAvg）[122]，如图2a所示。 在每次迭代中，服务器首先将当前的全局模型发送给选定的参与者。 然后，选定的各方使用其本地数据更新全局模型。 接下来，将更新的模型发送回服务器。 最后，服务器对接收到的所有本地模型求平均值，以获得新的全局模型。FedAvg重复上述过程，直到达到指定的迭代次数。 服务器的全局模型是最终输出。

尽管FedAvg是集中式FL框架，但Li等人提出了SimFL。  [105]代表分散的FL框架。 在SimFL中，不需要受信任的服务器。 在每次迭代中，各方首先更新其本地数据的梯度。 然后，将渐变发送给选定的参与者。 接下来，所选参与方使用其本地数据和渐变来更新模型。 最后，模型被发送给所有其他各方。为了确保公平并利用来自不同方的数据，选择每一方以大约相同的回合数来更新模型。  SimFL重复指定的迭代次数并输出最终模型。

一个有挑战性和重要的方向是研究计算和通信成本之间的权衡。 具体而言，人们可能想知道收敛速度，两个通信回合之间的局部计算迭代以及总通信回合之间的关系。最近，李等人。  [108]对FedAvg在非IID数据分布上的收敛性做了很好的研究。他们的理论表明，收敛速度与局部迭代总数（即两个通信回合之间的局部计算迭代乘以总通信回合）成反比。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsfigure2.PNG)

-------------------------

​                                                                                                  图2：联合学习框架

另一个值得注意的方面是，除模型参数之外，可能还需要更多信息来进行计算和通信，以满足隐私保证。 模型参数容易受到推理攻击，并可能暴露有关训练数据的敏感信息[160、130、60]。 一种可能的解决方案是安全的多方计算[110，68]，它使各方可以在其输入上共同计算功能，同时将这些输入保持私有。 但是，加密的计算开销和发送密钥的通信开销很大，并且可能成为整个FL过程的瓶颈。 因此，效率是FLS的重要指标，许多人一直在努力减少开销，尤其是减少通信规模[95，122，156，26]。

### 4 分类

考虑到不同FLS的通用系统抽象和构造块，我们从六个方面对FLS进行分类：数据分区，机器学习模型，隐私机制，通信体系结构，联盟规模和联盟动机。 这些方面包括先前的FLS [158，97]中的共同因素（例如，数据分区，通信体系结构）和FLS的独特考虑因素（例如，机器学习模型和隐私机制）。 此外，这些方面可以用来指导FLS的设计。 图3显示了FLS的分类法摘要。

让我们用一个直观的例子来解释这六个方面。 不同地区的医院都希望进行FL，以提高对肺癌的预测任务的性能。 然后，必须考虑六个方面来设计这种FLS。

![](https://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsfigure3.PNG)

---------------------------

​                                                                                      图3：联合学习系统的分类

- **数据分区.**我们应该研究患者记录如何在医院之间分配。 尽管医院可能有不同的患者，但他们对于普通患者也可能有不同的知识。 因此，我们必须利用FL中的非重叠实例和功能。
- **机器学习模型.**我们应该弄清楚该任务应采用哪种机器学习模型。 例如，如果我们要对诊断图像执行分类任务，则可能需要在FL中训练卷积神经网络。
- **隐私机制.**我们必须决定使用什么技术来保护隐私。 由于患者记录非常私人，因此我们可能必须确保不能通过交换的梯度和模型来推断它们。 差异隐私是实现隐私保证的一种选择。
- **通讯架构.**我们必须确定通信体系结构。 如果存在受信任的服务器，则它可以是FL中的管理器。 否则，我们必须采用分散式设置。
- **联邦规模.**与移动设备上的FL不同，在这种情况下，我们具有相对较小的规模和良好的联盟稳定性。 而且，每一方都有相对较大的计算能力，这意味着我们可以容忍FL过程中进行更多的计算操作。
- **联邦动机.**我们应该考虑激励各方鼓励他们参加FL。 医院明确而直接的动机是提高肺癌预测的准确性。 然后，FL应该为每个参与方提供比本地培训更高准确性的模型。

#### 4.1 数据分区

基于数据在样本空间和特征空间上的分布方式，FLS通常可以分为水平FLS，垂直FLS和混合FLS [197]。

在水平FL中，不同组织的数据集具有相同的特征空间，但样本空间上的交集很少。 这是自然的数据分区，尤其是对于跨设备设置，在这种情况下，不同的用户尝试使用FL在同一任务上提高其模型性能。 同样，大多数FL研究采用水平划分。 由于本地数据具有相同的特征空间，因此各方可以使用相同的模型体系结构使用其本地数据来训练本地模型。 关键的挑战是如何在本地或全球培训中汇总不同方的信息。 如图2所示，FedAvg直接对所有本地模型求平均，这既简单又有效。 唤醒词识别[98]，例如“ Hey Siri”和“ OK Google”，是水平分区的典型应用，因为每个用户用不同的声音说同一句话。

在垂直FL中，不同组织的数据集具有相同或相似的样本空间，但特征空间不同。  Vaidya等。 在垂直划分的数据上提出了多个安全模型，包括关联规则挖掘[173]，k-means [174]，朴素贝叶斯分类器[175]和决策树[176]。 对于垂直FLS，它通常采用实体对齐技术[196，47]来收集组织的重叠样本。 然后，将重叠的数据用于使用加密方法训练机器学习模型。 程等。  [44]提出了一种无损垂直FLS，以使各方能够共同训练梯度提升决策树。 他们使用保护隐私的实体对齐来找到两方之间的共同用户，他们的梯度用于共同训练决策树。 政府机构之间的合作可以看作是纵向划分的情况。 假设税务部门需要存储在住房部门中的居民住房数据，以制定税收政策。 同时，住房部门还需要居民的税收信息，这些信息由税收部门保存，以适应他们的住房政策。 这两个部门共享相同的样本空间（即该国家的所有居民），但每个部门仅具有一部分特征（例如    住房或税务相关的个人数据）。

在许多其他应用中，尽管现有的FLS主要集中在一种分区上，但是各方之间的数据分区可能是水平分区和垂直分区的混合。 让我们以癌症诊断系统为例。 一组医院希望建立用于癌症诊断的FLS，但每个医院都有不同的患者以及不同种类的体检结果。 对于这种情况，转移学习[139]是一种可能的解决方案。 刘等。  [114]提出了一种安全的联合转移学习系统，该系统可以使用常见实例来学习各方特征之间的表示。

#### 4.2 机器学习模型

由于FL用于解决机器学习问题，因此各方通常希望训练最先进的机器学习模型。 在开发新模型或将当前模型重塑到联邦环境方面已经进行了许多努力。 在这里，我们考虑当今广泛使用的模型。 现在，最流行的机器学习模型是神经网络（NN），在许多任务中，例如图像分类和单词预测[96，167]，都可以取得良好的效果。 关于联邦随机梯度下降的研究很多[122，182，25]，可用于训练NN。

另一个广泛使用的模型是决策树，它与NN相比训练效率高。 基于树的FLS设计用于训练单个或多个决策树（例如，梯度增强决策树（GBDT）和随机森林）。  GBDT最近特别流行，它在许多分类和回归任务中都有很好的表现。  Li等。  [103]和Cheng等。  [44]提出了分别针对水平和垂直分割数据的GBDT的FLS。

除了神经网络和树以外，线性模型（例如线性回归，逻辑回归，支持向量机）是经典且易于使用的模型。 有一些完善的线性回归和逻辑回归系统[134，77]。 与其他复杂模型（例如NN）相比，这些线性模型基本上很容易学习。

当前，基于随机梯度下降[122，94，150，184，182]，提出了许多FL框架，这是针对包括神经网络和线性回归在内的许多模型的典型优化算法。 但是，为了提高模型的有效性，我们可能必须利用模型架构来改进FL框架。 由于FL处于早期阶段，因此FLS仍需要更好地支持最新模型的差距。

#### 4.3 隐私机制

尽管本地数据未在FL中公开，但由于交换了模型参数，有时它不够安全，这可能会泄漏有关数据的敏感信息。 针对机器学习模型[180、60、30、160、130、124]的攻击有很多，例如模型反转攻击[60]和隶属推断攻击[160]，它们可以通过访问原始数据来推断原始数据。 模型。 另外，当今有许多隐私机制，例如差异隐私[54]和k-匿名[56]，它们提供了不同的隐私保证。 调查总结了现有隐私机制的特征[179]。 在这里，我们介绍了当前FLS中用于数据保护的两种主要方法：加密方法和差分隐私。

加密方法，例如同态加密[15、77、27、33、74、145、146、204、206、112]和安全的多方计算（SMC）[157、36、23、51、24、101，  [17、62、91、181、39、65]被广泛用于保护隐私的机器学习算法中。 基本上，各方必须在发送之前对消息进行加密，对加密的消息进行操作以及对加密的输出进行解密才能获得最终结果。 应用上述方法，通常可以很好地保护FLS的用户隐私[88，201，89，136，202]。 例如，SMC [68]保证除了输出之外，所有各方都不能学习任何东西。 但是，SMC容易受到推理攻击。 而且，由于附加的加密和解密操作，这样的系统遭受极高的计算开销。

差异性隐私[54，55]确保一条记录不会对函数的输出产生太大影响。 许多研究采用差异性隐私[35、18、9、192、208、78、104、171]来保护数据隐私，其中各方不知道个人记录是否参与了学习。通过将随机噪声添加到数据或模型参数[9、104、163]，差分隐私可为单个记录提供统计隐私保证，并防止对模型的推理攻击。 由于学习过程中的噪音，这种系统倾向于产生不太准确的模型。

注意，上述方法彼此独立，并且FLS可以采用多种方法来增强隐私保证[69，195]。 还有其他方法可以保护用户隐私。一种有趣的基于硬件的方法是使用受信任的执行环境（TEE），例如英特尔SGX处理器[149、137]，它可以确保内部加载的代码和数据受到保护。 可以在中央服务器内部使用这种环境，以提高其可信度。

尽管大多数现有的FLS都采用密码技术或差分隐私来实现良好的隐私保证，但是这些方法的局限性目前似乎难以克服。 在尝试最小化这些方法带来的副作用的同时，寻找保护数据隐私和灵活隐私要求的新颖方法也是一个不错的选择。 例如，刘等。  [114]采用较弱的安全模型[52]，可以使系统更加实用。

与隐私级别相关的威胁模型在FLS中也有所不同[119]。 攻击可以来自FL过程的任何阶段，包括输入，学习过程和学习模型。

- **输入.**恶意方可以在FL上进行数据中毒攻击[40、99、12]。 例如，当事方可以在学习之前修改特定类别的样本的标签，以使所学习的模型在该类别上表现不佳。
- **学习过程.**在学习过程中，各方可以执行模型中毒攻击[16，193]以上传设计的模型参数。 像数据中毒攻击一样，由于中毒的本地更新，全局模型的准确性可能非常低。 除了模型中毒攻击之外，拜占庭式故障[32、22、43、166]也是分布式学习中的常见问题，在这种情况下，各方可能表现得很差，并会随机上传更新。
- **学习模型.**如果发布了学习的模型，则可以对其进行推理攻击[60、160、124、130]。 服务器可以从交换的模型参数中推断出有关训练数据的敏感信息。 例如，成员推断攻击[160、130]可以推断训练中是否使用了特定的数据记录。 请注意，FL管理者也可以在学习过程中进行推理攻击，他可以访问各方的本地更新。

#### 4.4 通信架构

FLS中有两种主要的通信方式：集中式设计和分散式设计。在集中式设计中，数据流通常是不对称的，这意味着管理器将从其他方收集信息（例如，梯度或模型参数）并发送回培训结果[25]。全局模型上的参数更新始终在此管理器中完成。 管理者与本地方之间的通信可以是同步[122]或异步[194，164]。 在分散的设计中，通信在各方之间进行[208、103]，并且每一方都能够直接更新全局参数。

Google键盘[76]是集中式架构的一种情况。 服务器从用户的设备收集本地模型更新并训练全局模型，然后将其发送回用户以进行推断。 如图2a所示，集中式架构通常是简单有效的。 可扩展性和稳定性是集中式FL系统设计中的两个重要因素。 尽管集中式设计在现有研究中已广泛使用，但在某些方面，最好采用分散式设计，因为将信息集中在一台服务器上可能会带来潜在的风险或不公平性。 最近，考虑使用区块链[210]是一种流行的分散式平台。 设计FL的分散式系统仍然是一项挑战，同时在学习过程中，在通信方面，各方几乎都被平等对待，并且不需要信任的服务器。 医院中的分散癌症诊断系统就是分散架构的一个例子。 每家医院都共享经过训练的模型，该模型使用了来自其患者的数据，并获得了用于诊断的全局模型[28]。 在分散式设计中，主要挑战在于，很难设计出一种协议，该协议以合理的通信开销几乎公平地对待每个成员。 由于没有中央服务器，并且培训在各方中进行，因此该方可能必须从所有其他方收集信息，并且每个方的通信开销自然可以与方的数量成比例。

#### 4.5 联邦规模

根据联盟的规模，FLS可以分为两种典型类型：跨库FLS和跨设备FLS [85]。 它们之间的区别在于参与方的数量和每个参与方中存储的数据量。

在跨仓库FLS中，参与方是组织或数据中心。 通常有相对较少的参与方，并且每个参与方都具有相对大量的数据以及计算能力。例如，亚马逊希望通过培训从全球数百个数据中心收集的购物数据为用户推荐商品。 每个数据中心拥有大量数据以及足够的计算资源。 私有FLS面临的挑战之一是如何在隐私模型的约束下有效地将计算分配到数据中心[211]。

相反，在跨设备FLS中，参与方数量相对较大，并且每个参与方具有相对少量的数据以及计算能力[183]。 各方通常是移动设备。  Google Keyboard [198]是公共FLS的一个很好的例子。  Google尝试借助FL来改进Google键盘的查询建议。 有数百万个Android设备，每个设备仅具有其用户的数据。 同时，由于能耗问题，不能要求设备执行复杂的培训任务。 在这种情况下，系统应具有足够的功能来管理大量的参与者并处理可能的问题，例如设备与服务器之间的连接不稳定。

#### 4.6 联邦动机

在FL的实际应用中，各方需要动机来参与FLS。 动机可以是法规或激励措施。 公司或组织内部的FL通常受法规激励。 但是在许多合作中，不能强迫各方根据法规提供数据。 以Google键盘[198]为例，Google无法阻止不提供数据的用户使用Google键盘。 但是，那些同意上传输入数据的人可能会享受更高的单词预测准确度。 这种激励措施可以鼓励每位提供数据的用户改善整体模型的性能。 但是，如何设计这样一个合理的协议仍然具有挑战性。

激励机制设计对于FLS的成功非常重要。 在区块链中已经有一些成功的激励设计案例[213，57]。 系统内部的各方可以是合作者，也可以是竞争对手。 提出了诸如[87，86]之类的其他激励设计，以吸引具有FL高质量数据的参与者。 我们期望在FLSs下重新审视不同的博弈论模型[155，84，129]及其均衡设计。 即使是Google键盘，也需要激励用户参与此协作学习过程。

### 5 现有研究的总结

在本节中，我们将根据第4节中考虑的方面，总结和比较现有的FLS研究。

#### 5.1 方法

要发现关于FL的现有研究，我们在Google Scholar和arXiv3中搜索关键字“联邦学习”。 在这里，我们仅考虑计算机科学社区中已发表的研究。

由于联盟的规模和联盟的动机取决于问题，因此我们没有从这两个方面对现有研究进行比较。 为了便于演示，我们分别使用“ NN”，“ DT”和“ LM”来表示神经网络，决策树和线性模型。 此外，我们分别使用“ CM”和“ DP”来表示加密方法和差分隐私。 请注意，某些研究中的算法（例如联合随机梯度下降）可用于学习许多机器学习模型（例如逻辑回归和神经网络）。 因此，在“模型实现”列中，我们介绍了在相应论文中已经实现的模型。 此外，在“主要领域”列中，我们指出了论文研究的主要领域。

#### 5.2 单个研究

我们总结了现有的典型研究成果和最新研究成果，如表1所示。从表1中，我们得出以下四个主要发现。

首先，大多数现有研究都考虑了水平数据划分。 我们推测部分原因是，水平数据分区的实验研究和基准测试比垂直数据分区相对容易。 但是，垂直FL在现实世界中也很常见，尤其是在不同组织之间。 垂直FL可以实现不同各方之间的更多协作。 因此，应该对垂直FL付出更多的努力，以填补空白。

其次，大多数研究都考虑在没有任何隐私保证的情况下交换原始模型参数。如果将来发现对机器学习模型的更强大攻击，这可能是不对的。当前，提供隐私保证的主流方法是差分隐私和加密方法（例如，安全的多方计算和同态加密）。 差异性隐私可能会极大地影响最终模型的质量。 此外，密码方法带来大量计算和通信开销，并且可能是FLS的瓶颈。 我们期待以合理的隐私权保证价格便宜的方式来满足法规要求。

第三，集中式设计是当前实现的主流。 在其设置中需要信任的服务器。 但是，尤其是在跨库设置中，可能很难找到受信任的服务器。删除中央服务器的一种幼稚方法是各方共享模型参数给所有其他各方，并且每一方还在本地维护相同的全局模型。 与集中式设置相比，此方法带来更多的通信和计算成本。 对于分散式架构的实用FL，应该做更多的研究。

最后，FL的主要研究方向（也是挑战）是提高有效性，效率和隐私性，这也是评估FLS的三个重要指标。 同时，还有许多其他关于FL的研究主题，例如公平性和激励机制。 由于FL与许多研究领域相关，我们相信FL将吸引更多的研究人员，并且在不久的将来我们将看到更多有趣的研究。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemstable1.PNG)

---------------------------------------

表1：现有已发表研究之间的比较。  LM表示线性模型。  DM表示决策树。  NN表示神经网络。  CM表示加密方法。  DP表示差异隐私。

##### 5.2.1 有效的算法

尽管某些算法基于SGD，但其他算法是为一种或几种模型体系结构专门设计的。 因此，我们将它们分类为基于SGD的算法，并相应地对专用算法进行建模。

###### SGD-based  

如果我们将一方的本地数据视为一个批次，则可以通过在每个回合中执行单个批次梯度计算，轻松地在联合设置中实施SGD。 但是，这种方法可能需要大量的通信回合才能收敛。 为了减少通信回合的次数，第3.3节和图2a中介绍的FedAvg [122]现在是基于SGD的典型且实用的FL框架。 在FedAvg中，各方使用其本地模型的SGD进行多次培训。然后，将全局模型的权重更新为局部模型的权重的平均值。 全局模型被发送回各方以完成全局迭代。 通过平均权重，本地各方可以在其本地模型上执行多个步骤的梯度下降，因此与朴素的联邦SGD相比，可以减少通信回合的次数。

Konecn ˇ y等。  [[94]提出了联邦SVRG（FSVRG）。 联盟SVRG和联盟平均之间的主要区别是更新局部模型和全局模型的参数的方式（即步骤2和步骤4）。 用于更新模型权重的公式基于联邦SVRG中的随机方差减小梯度（SVRG）[82]和分布式近似牛顿算法（DANE）。 他们将算法与其他基线（例如CoCoA + [120]和简单的分布式梯度下降）进行了比较。 对于Logistic回归模型，他们的方法可以在相同的通信回合下获得更高的准确性。 联盟平均和联盟SVRG之间没有比较。

一些研究是基于FedAvg的目标函数的变化。 萨胡等。  [150]提出了FedProx，其中将近端项添加到局部客观损失以限制局部变化的幅度。 他们提供了有关FedProx收敛的理论分析。  Mohri等。  [127]提出了一个新的框架，称为不可知FL。 他们没有使关于均匀分布的损失（即来自本地客户端的数据分布中的平均分布）的损失最小化，而是尝试训练一个集中化的模型，该模型针对由客户端分布的混合所形成的任何可能的目标分布进行了优化。

最近，[115]提出了垂直FL的联邦随机块坐标下降（FedBCD）。 与FedAvg一样，各方在传达中间结果之前会先更新其本地参数多轮。 它们还为FedBCD提供收敛分析。

###### Neural Networks  

尽管可以使用SGD优化器来训练神经网络，但如果还可以利用模型体系结构，则可以潜在地增加模型实用性。  Yurochkin等。  [205]通过应用贝叶斯非参数机制[63]，为多层感知器开发了概率联邦神经匹配（PFNM）。他们使用Beta-Bernoulli过程通知匹配程序将本地模型组合为联合全局模型。 实验表明，他们的方法在IID和非IID数据分区上都可以胜过FedAvg。

Wang等。  [182]展示了如何将PFNM应用于CNN（卷积神经网络）和LSTM（长短期记忆网络）。 此外，他们通过展开模型体系结构，提出了具有分层匹配方案的联合匹配平均（FedMA）。 具体来说，他们每次都使用匹配平均来更新全局模型的一层，这也减小了通信规模。实验表明，FedMA在CNN和LSTM上具有比FedAvg和FedProx更好的性能[150]。

###### Trees  

除神经网络外，决策树还广泛用于学术界和工业界[38、90、58、104]。与神经网络相比，树的训练和推理效率很高。 但是，树参数不能通过SGD直接优化，这意味着基于SGD的FL框架不适用于学习树。 我们需要专门的树框架。 在树模型中，梯度提升决策树（GBDT）模型[38]非常受欢迎。 关于联合GBDT，有几项研究。

有一些关于水平联合GBDT的研究。 赵等。  [208]提出了GBDT的第一个FLS。 在他们的框架中，每个决策树都是本地培训的，无需各方之间的沟通。 在一次聚会中训练的树木被发送到下一个聚会，以连续训练许多树木。差异隐私用于保护决策树。  Li等。  [103]通过使用位置敏感的哈希[50]在联合GBDT的构建中利用相似性信息。 他们通过汇总相似实例的梯度来利用本地当事人的数据分布。 与安全的多方计算相比，在较弱的隐私模型中，它们的方法是有效和高效的。 刘等。  [117]提出了一种针对移动人群感知的联邦极限提升学习框架。 他们通过秘密共享来实现GBDT的隐私保护学习。

刘等。  [116]提出了联邦森林（Federated Forest），它可以在垂直FL环境下训练随机森林。在每个节点的构建中，具有相应拆分功能的参与方负责拆分样本并共享结果。 他们对通信数据进行加密以保护隐私。 他们的方法与非联合版本一样准确。

程等。  [44]提出了SecureBoost，一种用于垂直FL设置的GBDT的框架。 在他们的假设中，只有一方拥有标签信息。 他们使用实体对齐技术获取公共数据，然后构建决策树。 同态加性加密用于保护梯度。

###### Linear/Logistic Regression  

线性/逻辑回归可以使用SGD实现。 在这里，我们显示的不是基于SGD的研究，而是专门为线性/逻辑回归设计的研究。

在水平FL设置中，Nikolaenko等人。  [134]提出了一个保护隐私的岭回归系统。 他们的方法结合了同态加密和Yao的乱码来达到隐私要求。 需要额外的评估程序来运行算法。  Chen等。  [41]提出了一个保护隐私的岭回归系统。 他们的方法结合了安全求和和同态加密，以达到隐私要求。 他们在他们的方法和以前的最新技术方法之间提供了完整的通信和计算开销比较。

在垂直FL设置中，Sanil等人。  [153]提出了一个安全的回归模型。 他们专注于线性回归模型，并采用秘密共享来确保其解决方案的私密性。 哈代等。  [77]提出了两方垂直联合逻辑回归的解决方案。 他们使用实体解析和加性同态加密。 他们还研究了实体解析错误对学习的影响。

###### Others  

有许多研究将FL与其他机器学习技术相结合，例如多任务学习[147]，元学习[59]，强化学习[125]和转移学习[139]。

史密斯等。  [162]将FL与多任务学习相结合[31，207]。 他们的方法考虑了联盟环境中MTL的高通信成本，混乱和容错的问题。  Corinzia和Buhmann [49]提出了一种具有非凸模型的联合MTL方法。 他们将中央服务器和本地方视为贝叶斯网络，并使用变式方法进行推断。

Chen等。  [37]在FedAvg的学习过程中采用元学习。 双方没有在本地训练中采用模型不可知的元学习（MAML）[59]算法，而没有在本地训练中交换模型参数，而是交换了MAML的梯度。 江等。  [81]根据现有的MAML算法解释FedAvg。 此外，他们应用了Reptile算法[132]来微调FedAvg训练的全局模型。 他们的实验表明，元学习算法可以提高全局模型的有效性。

刘等。  [111]提出了终生的联邦强化学习框架。 通过采用转移学习技术，可以训练全局模型来有效地记住机器人所学到的知识。

###### Summary  

我们将上述工作总结如下。

- 由于基于SGD的框架已被广泛研究和使用，因此最近有更多的研究集中在模型专用FL上。 我们希望通过使用模型专用方法来获得更好的模型准确性。 此外，我们鼓励研究人员研究联合决策树模型（例如GBDT）。与神经网络相比，树模型具有较小的模型大小并且易于训练，这可以导致FL中较低的通信和计算开销。
- 关于FL的研究仍处于早期阶段。 尽管在联盟环境中对简单的神经网络进行了很好的研究，但很少有研究将FL用于训练最先进的神经网络，例如ResNeXt [121]和EfficientNet [169]。 如何在复杂的机器学习任务上设计有效且实用的算法仍然是一个挑战，并且是一个持续的研究方向。
- 虽然大多数研究都集中在水平FL上，但对于垂直FL仍然没有完善的算法。 但是，垂直联合设置在涉及多个组织的现实世界中很常见。我们期待在这个有前途的领域进行更多的研究。

##### 5.2.2 实用性增强

尽管第5.2.1节介绍了有效的算法，但在此我们提出旨在改善效率，隐私和公平性等其他方面的框架的研究。

###### Efficiency  

虽然可以使用高性能计算社区[188，189]中的现代硬件和技术[118，100，102]加快FL中的计算速度，但FL研究主要致力于在FL过程中减少通信规模。

Konecn ˇ y等。 文献[95]提出了两种方法，结构化更新和草图更新，以减少联合平均中的通信成本。 第一种方法限制了局部更新的结构，并将其转换为两个较小矩阵的乘法。 在学习过程中仅发送一个小矩阵。 第二种方法使用有损压缩方法来压缩更新。 他们的方法可以将通信成本降低两个数量级，同时收敛速度略有下降。  Zhu和Jin [212]设计了一种多目标进化算法，以最小化通信成本和全局模型测试错误。 考虑到通信成本的最小化和全球学习准确性的最大化为两个目标，他们将FL表示为双目标优化问题，并通过多目标进化算法对其进行求解。  Jeong等。  [79]提出了一种针对具有非IID本地数据的设备的FL框架。 他们设计了联邦蒸馏，其通讯大小取决于输出尺寸，而不取决于模型尺寸。 此外，他们提出了一种使用生成对抗网络（GAN）的数据增强方案，以使训练数据集成为IID。 许多其他研究还针对非IID数据设计了专门方法[209、108、113、200]。 萨特勒等。  [156]提出了一种新的压缩框架，称为稀疏三元压缩（STC）。 具体来说，STC使用稀疏化，分层，错误累积和最佳Golomb编码来压缩通信。 他们的方法对于非IID数据和大量参与者是可靠的。

###### Privacy and Attacks  

尽管在FL中未交换原始数据，但是模型参数也会泄漏有关训练数据的敏感信息[160、130、186]。 因此，为交换的本地更新提供隐私保证很重要。

差异隐私是一种提供隐私保证的流行方法。  Geyer等。  [64]在客户端级别的观点上，在联合平均中应用了差分隐私。 他们使用高斯机制扭曲梯度更新的总和，以保护整个客户的数据集而不是单个数据点。McMahan等。  [123]在长期短期记忆（LSTM）递归神经网络（RNN）的训练中部署联邦平均。 此外，他们使用用户级别的差异隐私来保护参数。  Bhowmick等。  [21]应用局部差分隐私来保护FL中的参数。 为了提高模型质量，他们考虑了一种实用的威胁模型，该模型希望对个人数据进行解码，但是事先没有多少信息。 有了这个假设，他们可以获得更大的隐私预算。

Bonawitz等。  [24]应用安全的多方计算来保护基于联合平均的本地参数。 具体来说，他们提出了一种安全的聚合协议，可以基于秘密共享安全地计算向量的总和[157]。 他们还讨论了如何将差异隐私与安全聚合相结合。

Truex等。  [172]结合了安全的多方计算和差分隐私，以保护FL。 他们使用差异性隐私向本地更新注入噪音。 然后，在将有噪声的更新发送到中央服务器之前，将使用Paillier密码系统对其进行加密[138]。

对于FL攻击，当前的研究主要集中在后门攻击上，后者旨在通过交换设计的本地更新来实现不良的全局学习模型。

Bagdasaryan等。  [16]对FL进行模型中毒攻击。 恶意方将攻击模型提交给服务器，以便全局模型可能过度适合后门数据。 安全的多方计算无法防止此类攻击，因为它旨在保护模型参数的机密性。  Bhagoji等。  [20]也研究了对FL的模型中毒攻击。 由于平均步骤将减少恶意模型的影响，因此它采用显式增强方法来增加承诺的权重更新。 谢等。  [193]提出了对FL的分布式后门攻击。 他们将全局触发模式分解为局部模式。 每个对抗方只采用一种本地模式。 实验表明，它们的分布式后门攻击性能优于中央后门攻击。

###### Fairness and Incentive Mechanisms  

Li等基于FedAvg考虑公平。  [106]提出q-FedAvg。 具体来说，它们根据各方模型表现的差异来定义公平性。 如果这种方差较小，则该模型将更公平。 因此，他们设计了一个受α公平启发的新目标[13]。 基于联合平均，他们提出了q-FedAvg来解决其新目标。  q-FedAvg与FedAvg之间的主要区别在于用于更新模型参数的公式。

Kim等。  [93]将区块链架构与FL相结合。 他们基于联合平均，使用区块链网络交换设备的本地模型更新，该更新比中央服务器更稳定，并且可以为设备提供奖励。  Kang等。  [86]设计了一种基于信誉的工人选择方案，通过使用多权重主观逻辑模型来实现可靠的FL。 他们还利用区块链以分散的方式为具有抗抵赖和防篡改属性的工人实现安全的声誉管理。

###### Summary  

根据以上评论，我们将上述研究总结如下。

- 除了有效性，效率和隐私是FLS的另外两个重要因素。 与这三个领域相比，关于公平和激励机制的研究较少。 我们期待着更多关于公平和激励机制的研究，这些研究可以鼓励在现实世界中使用FL。
- 为了提高FLS的效率，通信开销仍然是主要挑战。大多数研究[95，79，156]试图减小每次迭代的通信量。 如何合理地设置交流回合的数量也是有前途的[212]。 计算和通信之间的权衡仍然需要进一步研究。
- 对于隐私保证，差分隐私和安全的多方计算是两种流行的技术。 但是，差异性隐私可能会严重影响模型质量，并且安全的多方计算可能非常耗时。 设计具有强大隐私保障的实用FLS仍然具有挑战性。 此外，针对中毒攻击的有效防御算法尚未得到广泛采用。

##### 5.2.3 应用

与FL相关的一个领域是边缘计算[133、203、143、53]，其中各方是边缘设备。许多研究试图将FL与移动边缘系统集成在一起。  FL在推荐系统[14，34]和自然语言处理[76]中也显示出令人鼓舞的结果。

###### Edge Computing  

Nishio和Yonetani [135]在实际的移动边缘计算（MEC）框架中实现了联合平均。 他们使用MEC framworks的运算符来管理异构客户端的资源。Wang等。  [185]在移动边缘计算系统中同时采用了分布式深度强化学习（DRL）和联邦学习。  DRL和FL的使用可以有效地优化移动边缘计算，缓存和通信。  Wang等。  [184]在资源受限的MEC系统上执行FL。 他们解决了如何在边缘有效地利用有限的计算和通信资源的问题。 使用联合平均，他们实现了许多机器学习算法，包括线性回归，SVM和CNN。

###### Recommender System  

Ammad-ud din等。  [14]制定了第一个联合协作过滤方法。 基于随机梯度方法，通过汇总本地更新在全局服务器中训练项目因子矩阵。他们凭经验表明，与集中式方法相比，联合方法几乎没有准确性损失。 柴等。  [34]设计了一个联邦矩阵分解框架。 他们使用联邦SGD来学习矩阵。 而且，它们采用同态加密来保护通信的梯度。

###### Natural Language Processing  

Hard等。  [76]将FL应用于移动键盘下一个单词的预测。 他们采用联合平均方法来学习LSTM的一种变体，称为耦合输入和忘记门（CIFG）[70]。 与基于服务器的日志数据训练相比，FL方法可以实现更好的精度召回。

###### Summary  

根据以上研究，我们得出以下总结。

- 边缘计算自然适合跨设备联合设置。 将FL应用于边缘计算的一个重要问题是如何有效利用和管理边缘资源。  FL的使用可以给用户带来好处，尤其是在改善移动设备服务方面。
- FL可以解决许多传统的机器学习任务，例如图像分类和工作预测。 根据法规和“数据岛”的规定，联合设置可能是未来几年的常见设置。 随着FL的快速发展，我们相信在计算机视觉，自然语言处理和医疗保健领域将会有更多的应用。

##### 5.2.4 基准

基准对于指导FLS的开发非常重要。 目前，我们只能找到[29]提出的一个开源基准LEAF。  LEAF包括公共联合数据集，一系列统计和系统指标以及一组参考实现。 但是，它缺乏评估FLS隐私和效率的指标。 而且，LEAF的当前实验仅限于几种FL实施，这还不够全面。

#### 5.3 开源系统

在本部分中，我们介绍了四个开源FLS：联合AI技术启动器（FATE），Google TensorFlow联合（TFF），OpenMined PySyft和百度PaddleFl。

##### 5.3.1 FATE

FATE是工业级别的FL框架，旨在在不同组织之间提供FL服务。  FATE的总体结构如图4所示。它具有六个主要模块：EggRoll，FederatedML，FATE-Flow，FATE-Serving，FATE-Board和KubeFATE。  EggRoll管理分布式计算和存储。 它为其他模块提供计算和存储AIP。  FederatedML包括联合算法和安全协议。 当前，它支持在水平和垂直联合设置下训练多种类型的机器学习模型，包括NN，GBDT和Logistic回归。 而且，它集成了安全的多方计算和同态加密，以提供隐私保证。  FATE-Flow是供用户定义其FL处理流程的平台。 管道可以包括数据预处理，联合培训，联合评估，模型管理和模型发布。  FATE-Serving为用户提供推理服务。 它支持加载FL模型并对其进行在线推断。  FATE-Board是FATE的可视化工具。 它提供了一种视觉方式来跟踪作业执行和模型性能。 最后，KubeFATE通过使用Docker或Kubernetes帮助在集群上部署FATE。 它提供定制的部署和群集管理服务。 通常，FATE是功能强大且易于使用的FLS。 用户只需设置参数即可运行FL算法。 此外，FATE提供了有关其部署和使用的详细文档。 但是，由于FATE提供了算法级别的接口，因此从业人员必须修改FATE的源代码以实现自己的联合算法。 对于非专业用户而言，这并不容易。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsfigure45.PNG)

-------------------------

##### 5.3.2 TFF  

TFF为基于TensorFlow的FL提供了构建模块。 如图5所示，它提供了两个不同层的API：FL API10和联合核心（FC）API11。 一方面，FL API提供了高级接口。 它包括三个关键部分，分别是模型，联合计算构建器和数据集。  FL API允许用户定义模型或仅加载Keras [72]模型。 联邦计算构建器包括典型的联邦平均算法。 此外，FL API提供了模拟的联合数据集以及用于访问和枚举FL本地数据集的功能。 另一方面，FC API包括较低级别的接口，作为FL流程的基础。 开发人员可以在联邦核心内部实现其功能和接口。 具体来说，FC作为Python程序包提供了Python接口，开发人员可以使用它们并编写新的Python函数。 为了易于使用（尤其是对于熟悉TensorFlow的开发人员），它支持许多类型，例如Tenser类型，序列类型，元组类型和函数类型。 最后，FC为FL提供了构建模块。 它支持多个联合运算符，例如联合和，联合约简和联合广播。 开发人员可以定义自己的运算符来实现FL算法。 总体而言，TFF是供开发人员设计和实施新的FL算法的轻量级系统。 当前，TFF仅支持FedAvg，不提供隐私机制。 现在，它只能部署在单台计算机上，在该计算机上，联合设置是通过仿真实现的。

##### 5.3.3 PySyft  

PySyft，首先由Ryffel等提出。  [148]是一个python库，为开发人员提供接口以实现其训练算法。 虽然TFF基于TensorFlow，但PySyft可以与PyTorch和TensorFlow一起很好地工作。 尽管PySyft仅支持FedAvg算法，但它提供了多种隐私机制，包括安全的多方计算和差分隐私。 同样，它可以部署在单台计算机或多台计算机上，其中不同客户端之间的通信通过websocket API [161]。 但是，尽管PySyft提供了一组教程，但没有关于其界面和系统架构的详细文档。

##### 5.3.4 PaddleFL  

PaddleFL是基于PaddlePaddle 12的FLS，PaddlePaddle 12是百度开发的深度学习平台。PaddleFL的系统结构如图6所示。在编译时，有四个组件，包括FL策略，用户定义的模型和算法，分布式训练配置以及FL作业生成器。  FL策略包括水平FL算法，例如FedAvg。 垂直FL算法将在未来集成。 除了提供的FL策略外，用户还可以定义自己的模型和训练算法。 分布式训练配置在分布式设置中定义训练节点信息。  FL作业生成器为联合服务器和工作者生成作业。 在运行时，有三个组件，包括FL服务器，FL工作器和FL调度程序。 服务器和工作者分别是FL中的管理者和参与方。 调度员选择参加每一轮培训的工人。 目前，PaddleFL的开发仍处于早期阶段，文档和示例还不够清楚。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsfigure6.PNG)

--------------



##### 5.3.5 Others  

还有其他封闭源联合学习系统。  NVIDIA Clara 13已启用FL。 它采用集中式架构和加密的通信通道。  Clara FL的目标用户是医院和医疗机构[107]。 平安科技的目标是建立一个名为Hive的联邦学习系统，该系统主要针对金融行业。 尽管Clara FL提供了API和文档，但我们找不到Hive的正式文档。

##### 5.3.6 Summary  

总体而言，FATE和PaddleFL尝试提供算法级别的API供用户直接使用，而TFF和PySyft尝试提供更详细的构造块，以便开发人员可以轻松地实现其FL流程。 表2显示了开源系统之间的比较。 在算法级别，FATE是最全面的系统，在水平和垂直设置下都支持许多机器学习模型。  TFF和PySyft仅实现FedAvg，这是FL中的基本框架，如5.2节所示。  PaddleFL支持当前关于NN和逻辑回归的几种水平FL算法。
   与FATE和TFF相比，PySyft和PaddleFL提供了更多的隐私机制。  PySyft涵盖了TFF支持的所有列出的功能，而TFF基于TensorFlow，而PySyft与PyTorch更好地配合使用。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemstable2.PNG)

--------------

### 6 系统设计

图7显示了FLS设计中需要考虑的因素，包括有效性，效率，私密性和自治性。 接下来，我们解释这些因素并详细介绍设计指南。

![](https://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsfigure7.PNG)

---------



#### 6.1 Effectiveness  

FLS的核心是（多个）有效算法（算法）。 如表1所示，要从大量现有研究中确定要实施的算法，我们首先应检查各方的数据分区。 如果各方具有相同的特征但样本不同，则可以将FedAvg [122]用于NN，将SimFL [103]用于树。 如果各方具有相同的样本空间但特征不同，则可以将FedBCD [115]用于NN，将SecureBoost [44]用于树。

#### 6.2 Privacy 

FLS的一项重要要求是保护用户隐私。 在这里，我们分析管理器的可靠性。 如果经理诚实且不好奇，那么我们就不需要采用任何其他技术，因为FL框架可确保不交换原始数据。 如果经理诚实但好奇，那么我们就必须考虑可能的推理攻击。 模型参数还可以公开有关训练数据的敏感信息。 可以采用差分隐私[64、46、123]将随机噪声注入参数中，或者使用SMC [23、77、24]交换加密的参数。 如果管理器根本不能被信任，那么我们可以使用受信任的执行环境[42]在管理器中执行代码。 区块链也是扮演管理者角色的一种选择[93]。

#### 6.3 Efficiency 

效率在使系统流行方面起着关键作用。 为了提高效率，最有效的方法就是解决瓶颈。 如果瓶颈在于计算，我们可以使用功能强大的硬件，例如GPU [48]和TPU [83]。 如果瓶颈在于通信，则可以应用压缩技术[19、95、156]来减小通信大小。

#### 6.4 Autonomy  

实际的FLS必须考虑当事方的自治权。 参与方可能在FL流程中退出，尤其是在跨设备设置中。 因此，系统不能在每个单方上回复过多。 它应该容忍一小部分政党的失败。 而且，当事方可能是自私的，不愿意以高质量共享模型。 激励机制[86，87]可以鼓励各方的参与并提高最终模型的质量。

#### 6.5 The Design Guideline  

我们根据第4节中显示的分类法和设计因素得出开发FLS的指南。

第一步是通过从实际方案中分析系统方面来确定FL算法。 这些方面包括数据分区，联盟规模，通信体系结构和机器学习模型。 参与实体固定后，数据分区和联盟规模几乎固定。 假设用户想要进行FL操作以改善Google键盘的预测能力。 然后，在这种情况下，我们将进行水平数据分区和跨设备联合设置。 Google可以提供一个服务器来担任FL的经理，因此我们可以采用集中式通信架构。 因此，诸如FedAvg和FedMA之类的算法可以满足我们的要求。 由于LSTM在单词预测任务上表现良好，因此我们可以采用针对CNN和LSTM的专门设计的FedMA [182]算法来训练LSTM模型。

下一步是满足隐私要求。 尽管当前的法规没有对模型参数的传输施加明确的限制，但是FLS应该保护单个记录，如果它们非常敏感，则可以防止推理攻击。 例如，医院要对肺癌的预测任务进行FL。 患者记录应得到良好的保护，我们的FLS应采用差异性隐私或安全的多方计算技术。 没有隐私保证的FLS可能非常危险。

最后一步是考虑激励机制。 如果各方受规制进行FL的激励机制，则在FLS中不需要激励机制。 但是，为了设计生动的FLS，激励机制对于鼓励各方参与和贡献很重要。 激励机制的基本要求是确保当事方提供更多的贡献而获得更多的回报。区块链是提供稳定和可验证的激励机制的一种选择[93，86，87]。

### 7 案例分析

在本节中，我们根据分类法介绍了FL的几种实际应用，如表3所示。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemstable3.PNG)

---------------

#### 7.1 Mobile Service 

有许多公司为他们的移动用户提供预测服务，例如Google Keyboard [198]，Apple的表情符号建议和QuickType [170]。 这些服务给用户带来了很大的便利。 但是，训练数据来自智能手机等用户的边缘设备。 如果公司从所有用户那里收集数据并训练全局模型，则可能会导致隐私泄漏。 另一方面，每个单个用户的数据不足以训练准确的预测模型。  FL使这些公司能够在不访问用户原始数据的情况下训练准确性预测模型，这意味着可以保护用户的隐私。 在FLS的框架中，用户计算并发送其本地模型而不是原始数据。 这意味着Google键盘用户可以享受下一个单词的准确预测，而无需共享其输入历史记录。 如果FLS可以广泛应用于此类预测服务，则由于数据始终存储在边缘，因此数据泄漏将大大减少。

在这种情况下，数据通常在数百万个设备上水平分割。 因此，单个设备计算资源和带宽的限制是两个主要问题。 此外，由于用户可以随时加入或离开系统，因此还应考虑系统的健壮性。 换句话说，应针对此类预测服务设计水平数据上的集中式跨设备FLS。

尽管FLS的基本框架可以以某种方式保护个人的隐私，但它可能无法抵御推理攻击[160]。 应该利用一些其他的隐私机制（例如差异性隐私）来确保个人的可分辨性。 在这里，安全的多方计算可能不合适，因为每个设备的计算能力都很弱并且无法承担昂贵的加密操作。 除了保证用户的隐私外，还应该开发一些激励机制来鼓励用户贡献自己的数据。 实际上，这些激励措施可以是优惠券或其他服务。

#### 7.2 Healthcare  

现代卫生系统要求研究机构，医院，联邦机构之间进行合作，以改善国家的卫生保健[61]。 此外，面对像COVID-19 [7]这样的全球卫生紧急情况，国家之间的合作研究至关重要。 这些卫生系统的主要目的是训练一种诊断疾病的模型。 这些诊断模型应尽可能准确。 但是，在某些法规（例如GDPR [11]）下，患者的信息不允许传输。 数据的隐私在国际合作中更加受到关注。 如果不解决隐私问题，合作研究可能会停滞不前，威胁到公共健康。 这种协作中的数据隐私很大程度上基于保密协议。 但是毕竟，该解决方案基于“信任”，这是不可靠的。  FL使合作成为可能，因为它可以从理论上确保隐私，这是可证明的并且可靠的。 这样，每个医院或机构只需共享局部模型即可获得准确的诊断模型。

在这种情况下，医疗保健数据在水平和垂直方向上都被划分：每一方都包含用于特定目的（例如患者治疗）的居民健康数据，但是每一方使用的功能各不相同。 参与方的数量有限，并且每个参与方通常都有大量的计算资源。 换句话说，需要对混合分区数据进行私有FLS。 最具挑战性的问题之一是如何训练混合分区数据。  FLS的设计可能比简单的水平系统更为复杂。 在医疗保健联合会中，可能没有中央服务器。 因此，另一个具有挑战性的部分是分散式FLS的设计，它对于某些不诚实或恶意的当事人也应具有强大的功能。 此外，可以通过诸如安全的多方计算和差异隐私之类的附加机制来解决隐私问题。 协作主要受法规激励。

#### 7.3 Finance  

金融联合会由银行，保险公司等组成。他们通常希望在日常金融运营中开展合作。 例如，某些“不良”用户可能会将贷款从另一家银行借来的钱打包成一笔。 所有银行都希望避免这种恶意行为，同时又不泄露其他客户的信息。 此外，保险公司还希望向银行学习客户的声誉。 但是，“好客户”信息的泄漏可能会导致利益损失或某些法律问题。

如果我们拥有可信赖的第三方（例如政府），则可能发生这种合作。 但是在许多情况下，政府不参与联邦，或者政府并不总是受信任的。 因此，可以引入具有隐私机制的FLS。 在FLS中，可以通过理论证明的隐私机制来保证每个银行的隐私。

在这种情况下，财务数据通常按用户ID进行垂直分区。 在垂直划分的数据中训练分类器非常具有挑战性。 通常，培训过程可分为两个部分：隐私保护记录链接[177]和垂直联合培训。 第一部分旨在找到垂直分区数据之间的链接，并且已经进行了充分的研究。 第二部分旨在训练链接的数据而不共享每一方的原始数据，这仍然是一个挑战。 跨筒仓和分散设置在此联盟中应用。 同样，在这种情况下应采用某些隐私机制，并且参与者可能会受到兴趣的激励。

### 8 vision

在本节中，我们展示了未来的有趣方向。

#### 8.1 异质性

各方的异质性是FLS中的重要特征。 基本上，各方在可访问性，隐私要求，对联盟的贡献和可靠性方面可以有所不同。 因此，重要的是要考虑FLS中的此类实际问题。

**动态调度.**由于各方的不稳定，在学习过程中可能无法确定一方的数量。 但是，特别是对于跨部门的设置，许多现有研究中的政党数目是固定的，并且他们不考虑新政党进入或当前政党离开的情况。 该系统应支持动态调度，并具有在参与方数量发生变化时调整其策略的能力。 有一些研究解决此问题。例如，Google TensorFlow Federated [25]可以容忍设备的掉线。 而且，区块链[210]的出现可以成为多方学习的理想且透明的平台。 在这个方向上需要做更多的努力。

**多种隐私限制.**很少的工作考虑了FLS的隐私异质性，因为当事方具有不同的隐私要求。 现有系统采用技术来保护同一级别上所有各方的模型参数或梯度。 但是，各方的隐私限制通常在现实中有所不同。 设计一个FLS会很有趣，该FLS将根据双方的隐私限制来区别对待各方。 如果我们能够在不违反各方隐私限制的前提下最大限度地利用双方的数据，则学习型模型应该具有更好的性能。 异类差异隐私[10]在此类设置中可能有用。

**智能优势.**直观地，如果一方提供更多信息，则可以从FLS中获得更多收益。一个简单的解决方案是在各方之间达成协议，以使某些方为提供更多信息的其他方付费。 需要建立有代表性的激励机制。

**鲁棒性.**尽管可以使用FL中的差异隐私来提供保护以防止潜在的推理攻击，但还有其他危险的攻击，例如由于恶意方而导致的数据中毒和后门攻击。 沿着这条线，顾等人。  [71]提出了一种多方协作学习系统，以在可信赖的执行环境中实现模型的责任。  Ghosh等。  [66]考虑对拜占庭政党（或异常和对抗党）的模型鲁棒性。 另一种潜在的方法可以是区块链[142，92]。  Preuveneers等。  [142]提出了一种基于许可的基于区块链的FL方法，以监视对异常检测机器学习模型的增量更新。

#### 8.2 系统发展

为了促进FLS的发展，除了详细的算法设计之外，我们还需要从更高的角度进行研究。

**系统架构.**像深度学习中控制参数同步的参数服务器一样，需要研究一些常见的系统架构来进行FL。 尽管FedAvg是一个广泛使用的框架，但适用的方案仍然有限。 例如，如何在无人监督的环境中进行联合学习？ 另外，除了模型平均以外，还有其他聚合方法吗？我们需要一个通用的系统架构，该架构提供了许多聚合方法和针对不同设置的学习算法。

**模型市场.**FL的一个可能变体是我们维持一个供买卖的模型市场。当事人可以购买模型以在本地进行模型聚合。 此外，它还可以通过附加信息（例如目标任务）将其模型推向市场。 这样的设计为联合会带来了更大的灵活性，并且对于组织来说也更容易接受，因为FL就像几笔交易一样。 在此类系统中，对模型进行良好的评估非常重要。 激励机制可能会有所帮助[191，86，87]。

**基准.**随着越来越多的FLS开发，具有代表性数据集和工作量的基准对于评估现有系统和指导未来的开发非常重要。  Caldas等。  [29]提出了LEAF，这是一个基准，包括联邦数据集，评估框架和参考实现。 郝等。  [75]提出了一个具有FL支持的名为Edge AIBench的计算测试平台，并讨论了基准套件中包括的四个典型方案和六个测量组件。尽管如此，更多的应用程序和方案仍然是FLS成功的关键。

**数据生命周期.**学习仅仅是联邦系统的一个方面。 数据生命周期包括多个阶段，包括数据创建，存储，使用，共享，存档和销毁。 为了保证整个应用程序的数据安全性和私密性，我们需要在FL环境下发明新的数据生命周期。 尽管数据共享显然是关注的阶段之一，但FLS的设计也影响其他阶段。 例如，数据创建可以帮助准备适合FL的数据和功能。

#### 8.3 FL in Domains  

**物联网.**由于物联网应用程序的部署日益增多，安全性和隐私问题已成为雾计算和边缘计算的热门研究领域。 有关更多详细信息，读者可以参考最近的一些调查[165、199、128]。  FL可能是解决数据隐私问题的一种潜在方法，同时仍提供相当不错的机器学习模型[109，131]。 其他关键挑战来自计算和能量约束。 隐私和安全性机制引入了运行时开销。 例如，江等。  [80]应用独立的高斯随机投影来改善数据隐私，然后深度网络的训练可能会太昂贵。作者需要开发新的资源调度算法，以将工作负载转移到具有更多计算能力的节点上。 类似的问题也发生在其他环境中，例如车对车网络[151，154]。

**规章制度.**虽然FL允许在不暴露原始数据的情况下进行协作学习，但仍不清楚FL如何遵守现有法规。 例如，GDPR建议对数据传输进行限制。 由于模型和渐变实际上不够安全，因此这种限制是否仍然适用于模型或渐变？ 此外，由于全局模型是局部模型的平均，因此很难执行“解释权”。  FL模型的可解释性是一个公开的问题，Gunning [73]，Samek等。  [152]。 此外，如果用户想要删除其数据，是否应该在没有数据的情况下重新训练全局模型[67]？  FL技术与实际法规之间仍然存在差距。 我们可能期望计算机科学界和法律界之间的合作。

### 9 结语

已经致力于开发联合学习系统（FLS）的许多努力。 现有FLS的完整概述和摘要非常重要且有意义。 受以前的联邦系统的启发，我们已经表明，异质性和自治性是实际FLS设计中的两个重要因素。此外，我们从六个不同方面为FLS提供了全面的分类。 基于这些方面，我们还介绍了现有FLS之间的功能和设计比较。 更重要的是，我们指出了许多机遇，从更多基准测试到新兴平台（如区块链）的集成。  FLS将是一个令人兴奋的研究方向，需要机器学习，系统和数据隐私社区的努力。

![](http://raw.githubusercontent.com/beichen777/paperimage/main/ASurveyonFederatedLearningSystemsend.jpg)

